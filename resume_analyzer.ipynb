{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b547a430-b60b-46d4-bf85-77ce03d16f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\user\\anaconda3\\lib\\site-packages (0.11.7)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\user\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\user\\anaconda3\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pdfminer.six==20250506 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pdfplumber) (20250506)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pdfplumber) (11.1.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pdfplumber) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (44.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\user\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber pytesseract pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "952ca9dc-89e4-4382-8a71-7acfe2030299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5428504-2da0-493d-b90a-81a2c66714e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text =\"\"\n",
    "    try:\n",
    "        # Try direct text extraction \n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text\n",
    "        if text.strip():\n",
    "            return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Direct text extraction fail : {e} \")\n",
    "    # fall back to OCR  for image-based PDFs\n",
    "    print (\"Failing back to OCR for image-based PDF\")\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path)\n",
    "        for image in images:\n",
    "            page_text = pytesseract.image_to_strict(image)\n",
    "            text += page_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f'OCR failed: {e}')\n",
    "    return text.strip()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2c6d48c-dc84-488e-870f-76b9cb370560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Text from PDF:\n",
      "KATE NGUYEN\n",
      "Email: nghoangky44@gmail.com | LinkedIn: linkedin.com/in/ky-kate-nguyen | Phone: (214)-771-5168\n",
      "GitHub: github.com/hoangky0403\n",
      "Education\n",
      "University of North Texas, Denton, Texas\n",
      "M.S. in Data Science (Expected Summer 2027)\n",
      "Coursework: Knowledge Management Tools and Technologies, Principles and Techniques for Data Science,\n",
      "Fundamentals of Data Science\n",
      "Florida International University, Miami, Florida\n",
      "B.B.A in International Business and Finance, GPA: 3.86/4.0 (May 2019)\n",
      "Coursework: Intermediate Financial Management, Financial Systems, Business Process Management\n",
      "Professional Experience\n",
      "Keyrus - Business Consultant (Jan 2022 – May 2025)\n",
      " Led 1 full-cycle Anaplan implementation for enterprise clients and supported 3 additional projects.\n",
      " Conducted quantitative analysis and built dashboards, improving forecasting efficiency and reducing\n",
      "manual effort by 40%.\n",
      " Designed and optimized financial data models to support corporate strategy and CAPEX initiatives.\n",
      " Supported cross-functional teams with technical documentation and system testing for business\n",
      "planning applications.\n",
      "Publicis Groupe - Finance Associate (Sep 2019 – Sep 2021)\n",
      " Processed and validated invoices with 98% accuracy to maintain compliance and integrity.\n",
      " Extracted and transformed financial data to support profitability analysis and cost control strategies.\n",
      " Analyzed financial data to support profitability reviews and cost control measures across 3\n",
      "departments.\n",
      "Projects (GitHub)\n",
      " Personalized Movie Recommender System – Developed a content-based movie recommendation\n",
      "system using Python and scikit-learn. Transformed movie metadata into numerical vectors and\n",
      "computed cosine similarity to generate top-5 recommendations. Built an interactive Streamlit app for\n",
      "real-time user selection with posters retrieved via TMDB API, optimized for a dataset of 5,000+ movies.\n",
      " Coffee Orders Analysis – Identified revenue drivers and customer trends using Excel Power Pivot.\n",
      " HR Analytics – Applied statistical methods to analyze retention and workforce performance using\n",
      "Power BI.\n",
      " London Bikes Analytics – Analyzed and visualized bike ride data in London using Python and\n",
      "Tableau.\n",
      "Skills & Certifications\n",
      " Data & Analytics: Python (pandas, scikit-learn, NumPy), SQL, Data Modeling, Statistical Analysis,\n",
      "ETL, Feature Engineering, Machine Learning (Content-Based Recommendation Systems)\n",
      " Visualization & Tools: Streamlit, Power BI, Tableau, Excel (Advanced), Jupyter Notebook, ERP/EPM\n",
      "Systems\n",
      " Business & Strategy: Financial Modeling, Market/Competitor Research, Process Optimization,\n",
      "Forecasting & Dashboards\n",
      " Certifications: Anaplan Solution Architect, SQL & Python for Data Analysis, Applied Data Science Lab\n",
      "(In Progress)\n"
     ]
    }
   ],
   "source": [
    "pdf_path = r\"C:\\Users\\User\\OneDrive\\Desktop\\HOANGKY NGUYEN\\Job\\DATA\\Kate Nguyen - Resume.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "print(\"\\nExtracted Text from PDF:\")\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f239f3f4-52f9-417e-b3b0-59b899520984",
   "metadata": {},
   "source": [
    "Set Google GenerativeAI Api Key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94aecc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google.generativeai in c:\\users\\user\\anaconda3\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\user\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google.generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\user\\anaconda3\\lib\\site-packages (from google.generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\user\\anaconda3\\lib\\site-packages (from google.generativeai) (2.181.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google.generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\anaconda3\\lib\\site-packages (from google.generativeai) (5.29.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\user\\anaconda3\\lib\\site-packages (from google.generativeai) (2.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from google.generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from google.generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google.generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core->google.generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core->google.generativeai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google.generativeai) (0.4.8)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-python-client->google.generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-python-client->google.generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-python-client->google.generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google.generativeai) (3.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic->google.generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic->google.generativeai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->google.generativeai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google.generativeai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1800b1b4-0ab2-45df-b742-1be6dcad472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "genai.configure(api_key = os.getenv(\"GOOGLE_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "634ba7ec-0e2f-422b-bc13-87f1de7776bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"What is the capital of USA?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6232848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"The capital of the USA is **Washington, D.C.**\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.005602954753807613\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 7,\n",
      "        \"candidates_token_count\": 14,\n",
      "        \"total_token_count\": 21\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-flash\"\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04b43eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the USA is **Washington, D.C.**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda5e149",
   "metadata": {},
   "source": [
    "Resume Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6eaa6213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_resume(resume_text, job_desciption=None):\n",
    "    if not resume_text:\n",
    "        return {\"error\": \"Resume text is required for analysis\"}\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "    base_prompt = f\"\"\"\n",
    "    You are an experienced HR headhunter with technical experience in the field of the following job roles: \n",
    "    Data Sciencist, Data Analyst, Machine Learning Engineer, Data Engineer, Bussiness Analyst, your task is \n",
    "    to review the provided resume. Please share proffessional feedback on whether the candidate profile matches\n",
    "    with the role. In addition, mention the skills the candidate alreayd have and mention some skills that need\n",
    "    improvement, also suggest some courses/projects the candidate can do to improve their profile.\n",
    "\n",
    "    Resume:\n",
    "    {resume_text}\n",
    "\"\"\"\n",
    "    if job_desciption:\n",
    "        base_prompt += f\"\"\"\n",
    "        In addition, compare this resume to the following description:\n",
    "        Job Description:\n",
    "        {job_desciption}\n",
    "        \"\"\"\n",
    "    response = model.generate_content(base_prompt)\n",
    "\n",
    "    analysis = response.text.strip()\n",
    "    return analysis \n",
    "                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f2b7496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Resume Review for Kate Nguyen\n",
      "\n",
      "Kate Nguyen's resume presents a promising profile, particularly for roles bridging business analysis and data science. However,  her experience leans more towards Business Analyst/Data Analyst roles than  Data Scientist or Machine Learning Engineer roles.  Let's break down the strengths and weaknesses:\n",
      "\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "* **Strong Business Acumen:** Kate demonstrates a solid understanding of business processes, financial modeling, and strategic planning through her experience at Keyrus and Publicis Groupe.  The Anaplan implementation experience is a significant asset, highlighting project management skills and experience with enterprise-level data systems.  Her quantifiable achievements (e.g., 40% efficiency improvement) are compelling.\n",
      "* **Relevant Technical Skills:** She possesses a good foundation in Python (pandas, scikit-learn, NumPy), SQL, data modeling, and data visualization tools (Tableau, Power BI, Streamlit).  Her projects showcase practical application of these skills.\n",
      "* **Project Portfolio:** The GitHub projects, while relatively small in scale, demonstrate initiative and practical application of data science techniques. The Movie Recommender System is particularly noteworthy.\n",
      "* **Certifications:** The Anaplan Solution Architect certification is a significant credential in the EPM space.  The SQL & Python for Data Analysis certification further strengthens her profile.\n",
      "\n",
      "\n",
      "**Weaknesses:**\n",
      "\n",
      "* **Limited Machine Learning Experience:** While she mentions machine learning and has built a content-based recommender system, her expertise in this area appears relatively superficial compared to her business analysis skills.  The resume lacks evidence of experience with more advanced ML techniques, model deployment, or MLOps.\n",
      "* **Data Engineering Gaps:**  There's little indication of experience with big data technologies (Hadoop, Spark, etc.), data pipelines, or cloud-based data warehousing solutions (AWS, Azure, GCP).  This is a significant gap if aiming for Data Engineer or even senior Data Scientist roles.\n",
      "* **M.S. Still in Progress:**  While an M.S. in Data Science is a significant asset, it's still not completed. Recruiters may prioritize candidates with completed degrees, especially for more senior positions.\n",
      "* **Resume Structure:** While the information is present, a slightly more targeted resume structure would be beneficial. For example, grouping skills by job function would make it easier for recruiters to quickly assess her qualifications for specific roles.\n",
      "\n",
      "\n",
      "**Skills Kate Already Has:**\n",
      "\n",
      "* **Business Analysis:** Financial Modeling, Forecasting, Dashboarding, Process Optimization, Requirement Gathering, Stakeholder Management, Anaplan expertise.\n",
      "* **Data Analysis:** SQL, Python (Pandas, NumPy, Scikit-learn), Data Cleaning, ETL (basic), Statistical Analysis, Data Visualization (Tableau, Power BI, Streamlit).\n",
      "* **Data Science (Introductory):** Content-based recommendation systems.\n",
      "* **Project Management:** Leading Anaplan implementations, managing project timelines and deliverables.\n",
      "\n",
      "\n",
      "**Skills Needing Improvement:**\n",
      "\n",
      "* **Advanced Machine Learning:** Deep Learning, NLP, Time Series Analysis, Model Tuning, Model Deployment.\n",
      "* **Data Engineering:** Big Data technologies (Hadoop, Spark), Cloud platforms (AWS, Azure, GCP), Data Pipelines (e.g., Apache Airflow), Data Warehousing.\n",
      "* **Database Management:** Advanced SQL (optimizations, query tuning), NoSQL databases.\n",
      "\n",
      "\n",
      "**Suggested Courses/Projects:**\n",
      "\n",
      "* **Advanced Machine Learning Course:**  A course on Coursera, edX, Udacity, or DataCamp focusing on deep learning, NLP, or another advanced ML technique.\n",
      "* **Data Engineering Course/Bootcamp:**  Focus on cloud-based data warehousing and pipeline development using tools like AWS S3, EMR, Glue, or similar Azure/GCP services.\n",
      "* **Big Data Project:**  Work on a project involving a large dataset (e.g., from Kaggle), implementing a complete data pipeline, and applying advanced ML techniques.  Publicly share this project on GitHub.\n",
      "* **Database Management Project:**  Design and implement a database for a specific application, focusing on efficient query design and optimization.\n",
      "* **Portfolio Enhancement:** Revise her GitHub projects to be more robust and include more detailed documentation (explaining methodology, challenges, and results).  Consider adding projects showcasing skills in areas where she is weak.\n",
      "\n",
      "**Overall:**\n",
      "\n",
      "Kate has a strong foundation, especially in business analysis and introductory data science.  To broaden her appeal for Data Scientist, Data Engineer, or Machine Learning Engineer roles, she should focus on strengthening her skills in advanced machine learning and data engineering.  Completing her M.S. and showcasing these improved skills through enhanced projects and a revised resume will significantly boost her candidacy.  For now, she is a very strong candidate for Business Analyst or Data Analyst positions.\n"
     ]
    }
   ],
   "source": [
    "print(analyze_resume(resume_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e7ca15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
